# -*- coding: utf-8 -*-
"""Fine Tune Pre-train model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DflgQW6kwrISxGt2uMB0j27Gwz7NAWUI

Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.

By fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.

## The Data

<img src="x-rays_sample.png" align="center"/>
&nbsp

You have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders.

There are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library.
"""

from google.colab import drive
drive.mount('/content/drive')

# # Make sure to run this cell to use torchmetrics.
!pip install torch torchvision torchmetrics

# Import required libraries
# -------------------------
# Data loading
import random
import numpy as np
from torchvision.transforms import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torch.utils.data import random_split, DataLoader
import matplotlib.pyplot as plt

# Train model
import torch
from torchvision import models
import torch.nn as nn
import torch.optim as optim

# Evaluate model
from torchmetrics import  Accuracy, F1Score, Recall

# Set random seeds for reproducibility
torch.manual_seed(101010)
np.random.seed(101010)
random.seed(101010)

# Define the transformations to apply to the images.
transform_mean = [0.485, 0.456, 0.406]
transform_std =[0.229, 0.224, 0.225]
train_transform = transforms.Compose([transforms.ToTensor(),
                                transforms.RandomRotation((0,30)),
                                transforms.RandomHorizontalFlip(),
                                transforms.Normalize(mean=transform_mean, std=transform_std)])

val_test_transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=transform_mean, std=transform_std)])

# Apply the image transforms
train_dataset = ImageFolder("/content/drive/MyDrive/Colab Notebooks/CNN-Chest_X_Ray/data/chestxrays/train", transform=train_transform)
test_dataset = ImageFolder('/content/drive/MyDrive/Colab Notebooks/CNN-Chest_X_Ray/data/chestxrays/test', transform=val_test_transform)

# Create Validation Dataset
train_size = int(0.8 * len(train_dataset)) # 80% for training
val_size = len(train_dataset) - train_size # 20% for validation
train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

# Update transformation for validation sets.
val_dataset.dataset.transform = val_test_transform

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))
val_loader = DataLoader(val_dataset, batch_size = len(val_dataset))

# Import the Pre-Trained model
from torchvision import models
resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)

# Freeze all gradients in Pre-Trained model.
for param in resnet18.parameters():
    param.requires_grad = False

# Examine ResNet-18's structure
for name, layer in resnet18.named_children():
    print(name, layer)

# Modify the last fc layer for binary classification task
fc_in_features = resnet18.fc.in_features
resnet18.fc = nn.Linear(fc_in_features, 1, bias=True)

# Set required gradient for last fc layers
for param in resnet18.fc.parameters():
    param.requires_grad = True

# Training Loop
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(resnet18.parameters(), lr = 0.001, betas=(0.9,0.999))
num_epoch = 50
loss_values = [] # for loss visualizing

resnet18.train()

for epoch in range(num_epoch):
    running_loss = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        output = resnet18(inputs)
        outputs = resnet18(inputs).squeeze()
        loss = criterion(output, labels.float().view(-1,1))
        loss.backward()
        optimizer.step()

        # Update Accumulative Loss
        running_loss += loss.item()

    # Log Loss for visualization
    loss_values.append(loss.item())

    # Print Average Loss for each epoch
    epoch_loss = running_loss / len(train_loader)
    print(f'epoch:{epoch+1} / {num_epoch}, loss:{epoch_loss}')

# Visualize loss in training loop
plt.plot(loss_values)
plt.title('Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

#-------------------
# Evaluate the model
#-------------------

# Evaludation Function
def evaluate_model(model, data_loader):
    model.eval()  # Set the model to evaluation mode

    # Initialize metrics
    accuracy_metric = Accuracy(task="binary")
    recall_metric = Recall(task="binary")
    f1_metric = F1Score(task="binary")

    # Create lists to store all predictions and labels
    all_preds = []
    all_labels = []

    # Disable gradient calculation for evaluation
    with torch.no_grad():
        for inputs, labels in data_loader:
            outputs = model(inputs)
            preds = torch.sigmoid(outputs).round()  # Round to 0 or 1

            # Extend the lists with predictions and labels
            all_preds.extend(preds.tolist())
            all_labels.extend(labels.tolist())

    # Convert lists back to tensors after the loop
    all_preds = torch.tensor(all_preds)
    all_labels = torch.tensor(all_labels).view(-1,1)

    # Calculate performance metrics
    val_acc = accuracy_metric(all_preds, all_labels).item()
    val_recall = recall_metric(all_preds, all_labels).item()
    val_f1 = f1_metric(all_preds, all_labels).item()

    # Return the metrics
    return val_acc, val_recall, val_f1

# Evaluate on validation set.
val_accuracy, val_recall, val_f1 = evaluate_model(resnet18, val_loader)
print(f'Validation Accuracy: {val_accuracy:.4f}')
print(f'Validation Recall: {val_recall:.4f}')
print(f'Validation F1 Score: {val_f1:.4f}')

# Save parameters of the last fc layer.
torch.save(model.fc.state_dict(), "/content/drive/MyDrive/Colab Notebooks/CNN-Chest_X_Ray/20241103_finetune_LastLayerParameters.pth")
'''
Validation Accuracy: 0.9000
Validation Recall: 0.7778
Validation F1 Score: 0.8750
'''
# Later use on test set after completing hyperparameter tuning.